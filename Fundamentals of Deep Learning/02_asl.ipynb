{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DLI_Header.png\" style=\"width: 400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification of an American Sign Language Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will perform the data preparation, model creation, and model training steps we observed in the last section using a different dataset: images of hands making letters in [American Sign Language](http://www.asl.gs/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prepare image data for training\n",
    "* Create and compile a simple model for image classification\n",
    "* Train an image classification model and observe the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Sign Language Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [American Sign Language alphabet](http://www.asl.gs/) contains 26 letters. Two of those letters (j and z) require movement, so they are not included in the training dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/asl.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is available from the website [Kaggle](http://www.kaggle.com), which is a fantastic place to find datasets and other deep learning resources. In addition to providing resources like datasets and \"kernels\" that are like these notebooks, Kaggle hosts competitions that you can take part in, competing with others in training highly accurate models.\n",
    "\n",
    "If you're looking to practice or see examples of many deep learning projects, Kaggle is a great site to visit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is not available via Keras in the same way that MNIST is, so let's learn how to load custom data. By the end of this section we will have `x_train`, `y_train`, `x_valid`, and `y_valid` variables as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sign language dataset is in [CSV](https://en.wikipedia.org/wiki/Comma-separated_values) (Comma Separated Values) format, the same data structure behind Microsoft Excel and Google Sheets. It is a grid of rows and columns with labels at the top, as seen in the [train](asl_data/sign_mnist_train.csv) and [valid](asl_data/sign_mnist_valid.csv) datasets (they may take a moment to load).\n",
    "\n",
    "To load and work with the data, we'll be using a library called [Pandas](https://pandas.pydata.org/), which is a highly performant tool for loading and manipulating data. We'll read the CSV files into a format called a [DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) method that expects a csv file, and returns a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"asl_data/sign_mnist_train.csv\")\n",
    "valid_df = pd.read_csv(\"asl_data/sign_mnist_valid.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our data. We can use the [head](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.head.html) method to print the first few rows of the DataFrame. Each row is an image which has a `label` column, and also, 784 values representing each pixel value in the image, just like with the MNIST dataset. Note that the labels currently are numerical values, not letters of the alphabet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     12     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with MNIST, we would like to store our training and validation labels in `y_train` and `y_valid` variables. Here we create those variables and then delete the labels from our original dataframes, where they are no longer needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['label']\n",
    "y_valid = valid_df['label']\n",
    "del train_df['label']\n",
    "del valid_df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with MNIST, we would like to store our training and validation images in `x_train` and `x_valid` variables. Here we create those variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.values\n",
    "x_valid = valid_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the Training and Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 27,455 images with 784 pixels each for training..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...as well as their corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation, we have 7,172 images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and their corresponding labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the images, we will again use the matplotlib library. We don't need to worry about the details of this visualization, but if interested, you can learn more about [matplotlib](https://matplotlib.org/) at a later time.\n",
    "\n",
    "Note that we'll have to reshape the data from its current 1D shape of 784 pixels, to a 2D shape of 28x28 pixels to make sense of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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